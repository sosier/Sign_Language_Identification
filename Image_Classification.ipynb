{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "# General libraries / functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Classification libaries / functions\n",
    "from mlxtend.classifier import EnsembleClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Display libraries / functions\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickling functions\n",
    "def pickle_it(data, filename, python_version=3):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    data = the data you want to pickle (save)\n",
    "    filename = file name where you want to save the data\n",
    "    python_version = the python version where you will be opening the pickle file\n",
    "    \n",
    "    Out:\n",
    "    Saves a pickle file with your data to to the filename you specify\n",
    "    \"\"\"\n",
    "    with open(filename, \"wb\") as picklefile:\n",
    "        pickle.dump(data, picklefile, protocol=python_version)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    filename = name of the pickle file you want to open (e.g \"my_pickle.pkl\")\n",
    "    \n",
    "    Out:\n",
    "    Opens and returns the content of the picklefile to a variable of your choice\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as picklefile: \n",
    "        return pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "training_processed_zipped = load_pickle(\"training_processed_zipped.pkl\")\n",
    "train_images = training_processed_zipped[\"images\"]\n",
    "train_signs = training_processed_zipped[\"signs\"]\n",
    "\n",
    "# Load testing data\n",
    "test_processed_zipped = load_pickle(\"test_processed_zipped.pkl\")\n",
    "test_images = test_processed_zipped[\"images\"]\n",
    "test_signs = test_processed_zipped[\"signs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vectorize images (flatten to single row of pixels)\n",
    "if len(train_images) > 1:\n",
    "    train_images = pd.DataFrame([np.hstack((a.ravel(), b.ravel())) \\\n",
    "                                 for a, b in zip(train_images[0], train_images[1])]).fillna(0)\n",
    "    test_images = pd.DataFrame([np.hstack((a.ravel(), b.ravel())) \\\n",
    "                                for a, b in zip(test_images[0], test_images[1])]).fillna(0)\n",
    "else:\n",
    "    train_images = pd.DataFrame([img.ravel() for img in train_images[0]]).fillna(0)\n",
    "    test_images = pd.DataFrame([img.ravel() for img in test_images[0]]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Principal Components Analysis (PCA) to reduce feature space / dimensionality\n",
    "pca = PCA(n_components=188)  # Optimal n (as determined by grid search)\n",
    "pca.fit(train_images)\n",
    "\n",
    "train_images = pca.transform(train_images)\n",
    "test_images = pca.transform(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ALTERNATE FEATURE / DIMENSION REDUCTION APPROACH (RESTRICTED BOLTZMAN MACHINE):\n",
    "(NOT USED IN FINAL MODEL)\n",
    "\n",
    "rbm = BernoulliRBM(n_components=100, learning_rate=0.1, batch_size=10, n_iter=10, verbose=1)\n",
    "rbm.fit(train_images)\n",
    "\n",
    "train_images = rbm.transform(train_images)\n",
    "test_images = rbm.transform(test_images)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All individual models tried\n",
    "models = {\n",
    "        \"linear_SVM\": LinearSVC(penalty=\"l1\", C=0.61, dual=False),\n",
    "        \"SVM\": SVC(),\n",
    "        \"RBF SVM\": SVC(gamma=2, C=1),\n",
    "        \"KNN4\": KNeighborsClassifier(4),\n",
    "        \"decision_tree\": DecisionTreeClassifier(min_samples_leaf=32),\n",
    "        \"random_forest\": RandomForestClassifier(n_estimators=80),\n",
    "        # \"gaussianNB\": GaussianNB(),\n",
    "        # \"bernoulliNB\": BernoulliNB(),\n",
    "        # \"multinomialNB\": MultinomialNB(),\n",
    "        \"logistic\": LogisticRegression(\"l1\", C=0.16),\n",
    "        \"LDA\": LDA(),\n",
    "        \"QDA\": QDA(),\n",
    "        \"SGD_hinge\": SGDClassifier(loss=\"hinge\", penalty=\"l1\"),\n",
    "        \"SGD_huber\": SGDClassifier(loss=\"modified_huber\", penalty=\"l1\"),\n",
    "        \"SGD_log\": SGDClassifier(loss=\"log\", penalty=\"l1\"),\n",
    "        \"SGD_squared_hinge\": SGDClassifier(loss=\"squared_hinge\", penalty=\"l1\"),\n",
    "        \"SGD_perceptron\": SGDClassifier(loss=\"perceptron\", penalty=\"l1\"),\n",
    "        \"adaboost\": AdaBoostClassifier(n_estimators=200),\n",
    "        \"gradient_boosting\": GradientBoostingClassifier()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost\n",
      "Accuracy: 0.257966616085\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.21      0.16      0.18        97\n",
      "          B       0.42      0.30      0.35       102\n",
      "          C       0.32      0.17      0.22       112\n",
      "       Five       0.32      0.09      0.14       134\n",
      "      Point       0.23      0.67      0.35       119\n",
      "          V       0.18      0.13      0.15        95\n",
      "\n",
      "avg / total       0.28      0.26      0.23       659\n",
      "\n",
      "\n",
      "\n",
      "random_forest\n",
      "Accuracy: 0.283763277693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.25      0.30      0.27        97\n",
      "          B       0.43      0.21      0.28       102\n",
      "          C       0.48      0.26      0.34       112\n",
      "       Five       0.24      0.13      0.17       134\n",
      "      Point       0.24      0.70      0.36       119\n",
      "          V       0.42      0.08      0.14        95\n",
      "\n",
      "avg / total       0.34      0.28      0.26       659\n",
      "\n",
      "\n",
      "\n",
      "SGD_squared_hinge\n",
      "Accuracy: 0.376327769347\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.59      0.25      0.35        97\n",
      "          B       0.32      0.75      0.45       102\n",
      "          C       0.75      0.46      0.57       112\n",
      "       Five       0.33      0.16      0.21       134\n",
      "      Point       0.30      0.37      0.33       119\n",
      "          V       0.32      0.32      0.32        95\n",
      "\n",
      "avg / total       0.43      0.38      0.37       659\n",
      "\n",
      "\n",
      "\n",
      "SGD_huber\n",
      "Accuracy: 0.344461305008\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.58      0.23      0.33        97\n",
      "          B       0.33      0.76      0.46       102\n",
      "          C       0.76      0.42      0.54       112\n",
      "       Five       0.20      0.07      0.10       134\n",
      "      Point       0.24      0.36      0.29       119\n",
      "          V       0.29      0.29      0.29        95\n",
      "\n",
      "avg / total       0.39      0.34      0.33       659\n",
      "\n",
      "\n",
      "\n",
      "decision_tree\n",
      "Accuracy: 0.245827010622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.14      0.27      0.18        97\n",
      "          B       0.50      0.33      0.40       102\n",
      "          C       0.46      0.21      0.29       112\n",
      "       Five       0.21      0.12      0.15       134\n",
      "      Point       0.23      0.41      0.30       119\n",
      "          V       0.20      0.14      0.16        95\n",
      "\n",
      "avg / total       0.29      0.25      0.25       659\n",
      "\n",
      "\n",
      "\n",
      "SGD_hinge\n",
      "Accuracy: 0.349013657056\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.55      0.25      0.34        97\n",
      "          B       0.30      0.67      0.41       102\n",
      "          C       0.73      0.46      0.56       112\n",
      "       Five       0.28      0.12      0.17       134\n",
      "      Point       0.25      0.36      0.30       119\n",
      "          V       0.31      0.29      0.30        95\n",
      "\n",
      "avg / total       0.40      0.35      0.34       659\n",
      "\n",
      "\n",
      "\n",
      "linear_SVM\n",
      "Accuracy: 0.358118361153\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.55      0.25      0.34        97\n",
      "          B       0.32      0.67      0.43       102\n",
      "          C       0.66      0.46      0.54       112\n",
      "       Five       0.30      0.16      0.21       134\n",
      "      Point       0.25      0.35      0.29       119\n",
      "          V       0.33      0.31      0.32        95\n",
      "\n",
      "avg / total       0.40      0.36      0.35       659\n",
      "\n",
      "\n",
      "\n",
      "RBF SVM\n",
      "Accuracy: 0.180576631259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.00      0.00      0.00        97\n",
      "          B       0.00      0.00      0.00       102\n",
      "          C       0.00      0.00      0.00       112\n",
      "       Five       0.00      0.00      0.00       134\n",
      "      Point       0.18      1.00      0.31       119\n",
      "          V       0.00      0.00      0.00        95\n",
      "\n",
      "avg / total       0.03      0.18      0.06       659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanosier/anaconda/lib/python3.4/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/seanosier/anaconda/lib/python3.4/site-packages/sklearn/qda.py:133: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "QDA\n",
      "Accuracy: 0.215477996965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.34      0.12      0.18        97\n",
      "          B       1.00      0.04      0.08       102\n",
      "          C       0.90      0.08      0.15       112\n",
      "       Five       0.00      0.00      0.00       134\n",
      "      Point       0.19      0.98      0.32       119\n",
      "          V       0.00      0.00      0.00        95\n",
      "\n",
      "avg / total       0.39      0.22      0.12       659\n",
      "\n",
      "\n",
      "\n",
      "LDA\n",
      "Accuracy: 0.396054628225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.58      0.26      0.36        97\n",
      "          B       0.32      0.74      0.45       102\n",
      "          C       0.79      0.54      0.65       112\n",
      "       Five       0.32      0.19      0.23       134\n",
      "      Point       0.32      0.39      0.35       119\n",
      "          V       0.35      0.29      0.32        95\n",
      "\n",
      "avg / total       0.44      0.40      0.39       659\n",
      "\n",
      "\n",
      "\n",
      "SGD_perceptron\n",
      "Accuracy: 0.361153262519\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.53      0.24      0.33        97\n",
      "          B       0.32      0.75      0.45       102\n",
      "          C       0.72      0.48      0.58       112\n",
      "       Five       0.25      0.10      0.15       134\n",
      "      Point       0.26      0.34      0.29       119\n",
      "          V       0.34      0.33      0.33        95\n",
      "\n",
      "avg / total       0.40      0.36      0.35       659\n",
      "\n",
      "\n",
      "\n",
      "logistic\n",
      "Accuracy: 0.370257966616\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.64      0.30      0.41        97\n",
      "          B       0.29      0.61      0.40       102\n",
      "          C       0.71      0.52      0.60       112\n",
      "       Five       0.26      0.14      0.18       134\n",
      "      Point       0.30      0.44      0.35       119\n",
      "          V       0.32      0.25      0.28        95\n",
      "\n",
      "avg / total       0.41      0.37      0.37       659\n",
      "\n",
      "\n",
      "\n",
      "SGD_log\n",
      "Accuracy: 0.37784522003\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.58      0.27      0.37        97\n",
      "          B       0.33      0.74      0.46       102\n",
      "          C       0.75      0.48      0.59       112\n",
      "       Five       0.31      0.16      0.21       134\n",
      "      Point       0.28      0.35      0.31       119\n",
      "          V       0.31      0.33      0.32        95\n",
      "\n",
      "avg / total       0.42      0.38      0.37       659\n",
      "\n",
      "\n",
      "\n",
      "KNN4\n",
      "Accuracy: 0.289833080425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.21      0.14      0.17        97\n",
      "          B       0.26      0.27      0.27       102\n",
      "          C       0.50      0.19      0.27       112\n",
      "       Five       0.29      0.43      0.35       134\n",
      "      Point       0.38      0.46      0.42       119\n",
      "          V       0.16      0.17      0.16        95\n",
      "\n",
      "avg / total       0.31      0.29      0.28       659\n",
      "\n",
      "\n",
      "\n",
      "gradient_boosting\n",
      "Accuracy: 0.300455235205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.42      0.38      0.40        97\n",
      "          B       0.28      0.26      0.27       102\n",
      "          C       0.40      0.25      0.31       112\n",
      "       Five       0.18      0.11      0.14       134\n",
      "      Point       0.27      0.63      0.38       119\n",
      "          V       0.34      0.17      0.23        95\n",
      "\n",
      "avg / total       0.31      0.30      0.28       659\n",
      "\n",
      "\n",
      "\n",
      "SVM\n",
      "Accuracy: 0.385432473445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.66      0.30      0.41        97\n",
      "          B       0.33      0.68      0.45       102\n",
      "          C       0.66      0.51      0.58       112\n",
      "       Five       0.33      0.16      0.22       134\n",
      "      Point       0.32      0.48      0.39       119\n",
      "          V       0.25      0.21      0.23        95\n",
      "\n",
      "avg / total       0.42      0.39      0.37       659\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanosier/anaconda/lib/python3.4/site-packages/sklearn/lda.py:371: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(train_images, train_signs)\n",
    "    print(name)\n",
    "    print(\"Accuracy: %s\" % accuracy_score(test_signs, model.predict(test_images)))\n",
    "    print(classification_report(test_signs, model.predict(test_images)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final models selected to be included in ensemble model\n",
    "# Models to include can vary based on the input images, so should evaulate models to include in the ensemble each time\n",
    "ensemble_models = {\n",
    "        \"LDA\": LDA(),\n",
    "        \"SVM\": SVC()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble\n",
      "Accuracy: 0.412746585736\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.54      0.34      0.42        97\n",
      "          B       0.32      0.80      0.46       102\n",
      "          C       0.79      0.55      0.65       112\n",
      "       Five       0.39      0.20      0.27       134\n",
      "      Point       0.34      0.42      0.38       119\n",
      "          V       0.36      0.19      0.25        95\n",
      "\n",
      "avg / total       0.46      0.41      0.40       659\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanosier/anaconda/lib/python3.4/site-packages/sklearn/lda.py:371: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "master_model = EnsembleClassifier(ensemble_models.values())\n",
    "master_model.fit(train_images, train_signs)\n",
    "print(\"Ensemble\")\n",
    "print(\"Accuracy: %s\" % accuracy_score(test_signs, master_model.predict(test_images)))\n",
    "print(classification_report(test_signs, master_model.predict(test_images)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Current Best:**  \n",
    "*Ensemble SVM + LDA*  \n",
    "**41.3%** Accuracy\n",
    "\n",
    "**History:**\n",
    "1. Baseline: Dumb = 16.6%\n",
    "2. Best 1: Multinomial Naive Bayes = ~30%\n",
    " - *Initial image processing and models*\n",
    "3. Best 2: Logistic Regression = 32.6%\n",
    " - *More image processing*\n",
    "4. Best 3: Logistic Regression = 33.8%\n",
    " - *Inverted equalized hist color*\n",
    "5. Best 4: Ensemble Logistic + Linear SVM = 33.9%\n",
    "6. Best 5: Ensemble Logistic + Linear SVM = 35.5%\n",
    " - *Raw grayscale PCA = 100*\n",
    "7. Best 6: Ensemble Logistic + Linear SVM = 37.9%\n",
    " - *Optimized PCA = 188*\n",
    "8. Best 7: Ensemble Logistic + Linear SVM = 38.4%\n",
    " - *Optimized Logistic, C = 0.16*\n",
    "9. Best 8: Ensemble Logistic + Linear SVM = 38.5%\n",
    " - *Optimized Linear SVM, C = 0.61*\n",
    "10. Best 9: Ensemble Logistic + Linear SVM = 38.8%\n",
    " - *Inverted equalized hist color with circle*\n",
    "11. Best 10: Ensemble SVM + LDA = 41.3%\n",
    " - *Refined models included in ensemble model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opportunities for Additional Improvement\n",
    "- Image processing to better isolate the hand from background?\n",
    "- Feed multiple image types into the models (e.g. a grayscale image __*and*__ a skeletonized one)?\n",
    "- Refine ensemble model further by re-optimizing all included models for the latest image inputs?\n",
    "- Use voting/probability weights in the ensemble?\n",
    "- Neural networks (specifically convolutional)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
